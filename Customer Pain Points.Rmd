---
title: "Customer Pain Points"
author: "Lukas Lichtner & Andy Cao"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# packages we are using right now
library(tidyverse)
library(openxlsx)
library(visdat)


```

## Reading in the data
```{r Reading in the data}
dat <- read.xlsx("Hybridmobilität systemized.xlsx", sheet = "Labels", startRow = 2)
```

We've renamed each variable name to a shorter one, and marked variables which are not necessary with "X_" as a prefix. As such, we can now filter all the variables which has this prefix.
```{r Filtering out not needed variables}
dat <- dat %>% 
   select(-starts_with("X_"))
```

Further, we've named each "importance" metric with "IMP", and each "satisfaction" metric with "SAT". As each metric gets asked twice (one for importance and one for satisfaction), we've labeled them with the same number after the IMP or SAT prefix (e.g. SAT_1 and IMP_1 correspond to the same metric). We can filter for them as well, with their "ID" columns so combining them again. 
```{r Filter for importance and satisfaction ratings}
IMP_SAT <- dat %>% select("ID",
                          starts_with("SAT"),
                          starts_with("IMP"))
```

Additionally, we can filter for demographic variables, which are stored in the first 53 columns
```{r Reading in the data}

demographics <- dat %>% select("ID",
                               1:53)
```

Lastly, we can filter for the PR1 data, which might add additional demographic data
```{r Filter for additional demographics data}
PR_ratings <- dat %>% select("ID",
                             starts_with("PR1"))
```
## Cleaning the data

Now that we have 3 different datasets, we can start with datacleaning each of these datasets sepparately. We'll start with the importance and satisfaction scores (which we will then use to calculate the "pain" points).

### Cleaning Importance and Satisfaction Scores

As values are stored as "[number] = [interpretation]" in these metrics, and we only need the number, we extract the first character in these metrics and turn them into class numeric
```{r Extract first character from IMP_SAT}
IMP_SAT <- IMP_SAT %>% 
   mutate_at(.vars = vars(starts_with("SAT")),
             .funs = ~str_extract(string= ., pattern = "^.")) %>% 
   mutate_at(.vars = vars(starts_with("IMP")),
             .funs = ~str_extract(string= ., pattern = "^.")) %>% 
   mutate_if(.predicate = is.character,
             .funs = as.numeric)

IMP_SAT %>% head()
```

We can now calculate "paint point" scores for each of the 106 metrics, and to make this more efficient, we'll use pivot longer to have 3 columns: the first identifies whether it was a importance or a satisfaction rating, the second which metric number it was (1-106), and the values are the ratings themselves.
```{r Pivot longer IMP_SAT}
IMP_SAT_long <- IMP_SAT %>% 
   pivot_longer(cols = starts_with("IMP")| starts_with("SAT"),
                names_to = c("IMP/SAT","Metric_Nr"),
                values_to = "Rating",
                names_sep = "_")
IMP_SAT_long %>% head()
```

We'll have pivot this dataframe to a wider format (so we have IMP and SAT ratings, and metric number is still in a separate column) and calculate the differences for each metric and costumer, which functions as our pain point for each costumer.

```{r Pivot wider IMP_SAT and calculate pain points}
IMP_SAT_pain_points <- IMP_SAT_long %>% 
   pivot_wider(names_from = `IMP/SAT`,
               values_from = Rating) %>% 
   mutate(Diff = IMP-SAT)

IMP_SAT_pain_points %>% head()
```
Lastly, we can pivot this difference columns to a wider format again (so each person who filled out the survey has its own row again).
```{r}
Pain_points <- IMP_SAT_pain_points %>% 
   select(ID, Metric_Nr, Diff) %>% 
   mutate(Metric_Nr = as.numeric(Metric_Nr)) %>% 
   arrange(ID, Metric_Nr) %>% 
   pivot_wider(names_from = Metric_Nr,
               values_from = `Diff`)
   
```


### Cleaning Demographics

This is how our current demographic dataframe looks like:
```{r Visualize demographic dataset}
vis_dat(demographics, sort_type = FALSE)

```


First, we create a vector where the column number is stored if the cells contain "Ausgewählt" or "Nicht ausgewählt", as a means to recode them as numeric later on. 

```{r Create yes_no vector}
is_yes_no_question <- function(x) {
   vec <- c()
   counter <- 1
   
   for (i in 1:ncol(x)) {
      if (x[1, i] == "Ausgewählt" |
          x[1, i] == "Nicht ausgewählt") {
         vec[counter] <-  i
         counter <- counter + 1
      }
   }
   return(vec)
}

yes_no_cols <- is_yes_no_question(demographics)
yes_no_cols
```

We then recode said variables to 1 and 0 respectively.

```{r Using said vector, recode to 1 and 0}
demographics <- demographics %>% 
   rowwise() %>% 
   mutate_at(.vars = yes_no_cols, 
             .funs = ~if_else(. == "Ausgewählt", 1, 0))
```


In this section, we will clean demographic data in our dataset. We'll turn each character variable to a factor first.

```{r Create Factors out of character variables}
demographics <- demographics %>% mutate_if(is.character, factor)

```

Then we order the factors according to their proper order if it is ordinal scaled. This is a tedious step, as we have to look at each variable...

```{r Create Ordinal scaled factors if needed}
#levels: from smallest to biggest

demographics$transportation_pro_woche <-  factor(demographics$transportation_pro_woche, levels = c("Mehrmals in der Woche",
                                                                                                   "Täglich")
                                                 )
#still unsure:
#demographics$prozent_berufstätig <- factor(demographics$prozent_berufstätig)

demographics$nutzung_oev <-  factor(demographics$nutzung_oev, levels = c("Einmal im Monat oder seltener",
                                                                         "Mehrmals im Monat",
                                                                         "Einmal in der Woche",
                                                                         "Mehrmals in der Woche",
                                                                         "Täglich")
                                    )

demographics <- demographics %>% 
   mutate_at(.vars = vars(starts_with("aw_")),
             .funs = ~factor(. , levels = c("Nie",
                                            "Seltener",
                                            "Mehrmals im Monat",
                                            "Mehrmals pro Woche",
                                            "(fast) Täglich"))
             )

demographics <- demographics %>% 
   mutate_at(.vars = vars(starts_with("fz_")),
             .funs = ~factor(. , levels = c("Nie",
                                            "Seltener",
                                            "Mehrmals im Monat",
                                            "Mehrmals pro Woche",
                                            "(fast) Täglich"))
             )

#TO DO:
#
#neuen_Ort
#privates_auto
#ausflug_oev
#störungen_oev
#störungen_strasse
#technologische Entwicklung
```



## Analysis

We can now use kmeans clustering to get metric clusters. We will use a for loop to cluster the questions according to 2 to 10 clusters.  We then take the cluster where the F-value (ratio of between sum of squares and within sum of squares) is the largest. **Is this a good approach?** Are there alternatives?

```{r}
set.seed(42)
Fstat <- c()
for (i in seq(from = 2, to = 10, by = 1)){
   k <- i
   
   km_fit <- kmeans(Pain_points[,-1], centers = k)
   
   N <- nrow(Pain_points)
   
   Fstat[i-1] <- (km_fit$betweenss / (k-1)) / (km_fit$tot.withinss / (N-k))
}

which(Fstat == max(Fstat))

```

In this case, the F-value is largest in the first for loop, which means a cluster of 2 different questions are 


